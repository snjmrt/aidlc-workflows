# Build and Test
# Build and Test

# Build and Test

**Purpose**: Build all units and execute comprehensive testing strategy
**ç›®çš„**: ã™ã¹ã¦ã®ãƒ¦ãƒ‹ãƒƒãƒˆã‚’ãƒ“ãƒ«ãƒ‰ã—ã€åŒ…æ‹¬çš„ãªãƒ†ã‚¹ãƒˆæˆ¦ç•¥ã‚’å®Ÿè¡Œã™ã‚‹

**ç›®çš„**: ã™ã¹ã¦ã®ãƒ¦ãƒ‹ãƒƒãƒˆã‚’ãƒ“ãƒ«ãƒ‰ã—ã€åŒ…æ‹¬çš„ãªãƒ†ã‚¹ãƒˆæˆ¦ç•¥ã‚’å®Ÿè¡Œã™ã‚‹

## Prerequisites
- Code Generation must be complete for all units
- All code artifacts must be generated
- Project is ready for build and testing
## å‰ææ¡ä»¶
- ã™ã¹ã¦ã®ãƒ¦ãƒ‹ãƒƒãƒˆã§ Code Generation ãŒå®Œäº†ã—ã¦ã„ã‚‹ã“ã¨
- ã™ã¹ã¦ã®ã‚³ãƒ¼ãƒ‰æˆæœç‰©ãŒç”Ÿæˆæ¸ˆã¿ã§ã‚ã‚‹ã“ã¨
- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒãƒ“ãƒ«ãƒ‰ã¨ãƒ†ã‚¹ãƒˆã®æº–å‚™å®Œäº†

## å‰ææ¡ä»¶
- ã™ã¹ã¦ã®ãƒ¦ãƒ‹ãƒƒãƒˆã§ Code Generation ãŒå®Œäº†ã—ã¦ã„ã‚‹ã“ã¨
- ã™ã¹ã¦ã®ã‚³ãƒ¼ãƒ‰æˆæœç‰©ãŒç”Ÿæˆæ¸ˆã¿ã§ã‚ã‚‹ã“ã¨
- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒãƒ“ãƒ«ãƒ‰ã¨ãƒ†ã‚¹ãƒˆã®æº–å‚™å®Œäº†

---
---

---

## Step 1: Analyze Testing Requirements
## ã‚¹ãƒ†ãƒƒãƒ— 1: ãƒ†ã‚¹ãƒˆè¦ä»¶ã®åˆ†æ

## ã‚¹ãƒ†ãƒƒãƒ— 1: ãƒ†ã‚¹ãƒˆè¦ä»¶ã®åˆ†æ

Analyze the project to determine appropriate testing strategy:
- **Unit tests**: Already generated per unit during code generation
- **Integration tests**: Test interactions between units/services
- **Performance tests**: Load, stress, and scalability testing
- **End-to-end tests**: Complete user workflows
- **Contract tests**: API contract validation between services
- **Security tests**: Vulnerability scanning, penetration testing
ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’åˆ†æã—ã¦é©åˆ‡ãªãƒ†ã‚¹ãƒˆæˆ¦ç•¥ã‚’æ±ºå®š:
- **ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ**: Code Generation ã§ãƒ¦ãƒ‹ãƒƒãƒˆã”ã¨ã«ç”Ÿæˆæ¸ˆã¿
- **çµ±åˆãƒ†ã‚¹ãƒˆ**: ãƒ¦ãƒ‹ãƒƒãƒˆ/ã‚µãƒ¼ãƒ“ã‚¹é–“ã®ç›¸äº’ä½œç”¨ã‚’æ¤œè¨¼
- **æ€§èƒ½ãƒ†ã‚¹ãƒˆ**: è² è·ãƒ»ã‚¹ãƒˆãƒ¬ã‚¹ãƒ»ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£
- **E2E ãƒ†ã‚¹ãƒˆ**: å®Œå…¨ãªãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
- **å¥‘ç´„ãƒ†ã‚¹ãƒˆ**: ã‚µãƒ¼ãƒ“ã‚¹é–“ã® API å¥‘ç´„æ¤œè¨¼
- **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ†ã‚¹ãƒˆ**: è„†å¼±æ€§ã‚¹ã‚­ãƒ£ãƒ³ã€ãƒšãƒãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’åˆ†æã—ã¦é©åˆ‡ãªãƒ†ã‚¹ãƒˆæˆ¦ç•¥ã‚’æ±ºå®š:
- **ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ**: Code Generation ã§ãƒ¦ãƒ‹ãƒƒãƒˆã”ã¨ã«ç”Ÿæˆæ¸ˆã¿
- **çµ±åˆãƒ†ã‚¹ãƒˆ**: ãƒ¦ãƒ‹ãƒƒãƒˆ/ã‚µãƒ¼ãƒ“ã‚¹é–“ã®ç›¸äº’ä½œç”¨ã‚’æ¤œè¨¼
- **æ€§èƒ½ãƒ†ã‚¹ãƒˆ**: è² è·ãƒ»ã‚¹ãƒˆãƒ¬ã‚¹ãƒ»ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£
- **E2E ãƒ†ã‚¹ãƒˆ**: å®Œå…¨ãªãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
- **å¥‘ç´„ãƒ†ã‚¹ãƒˆ**: ã‚µãƒ¼ãƒ“ã‚¹é–“ã® API å¥‘ç´„æ¤œè¨¼
- **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ†ã‚¹ãƒˆ**: è„†å¼±æ€§ã‚¹ã‚­ãƒ£ãƒ³ã€ãƒšãƒãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

---
---

---

## Step 2: Generate Build Instructions
## ã‚¹ãƒ†ãƒƒãƒ— 2: ãƒ“ãƒ«ãƒ‰æ‰‹é †ã®ç”Ÿæˆ

## ã‚¹ãƒ†ãƒƒãƒ— 2: ãƒ“ãƒ«ãƒ‰æ‰‹é †ã®ç”Ÿæˆ

Create `aidlc-docs/construction/build-and-test/build-instructions.md`:
`aidlc-docs/construction/build-and-test/build-instructions.md` ã‚’ä½œæˆ:

`aidlc-docs/construction/build-and-test/build-instructions.md` ã‚’ä½œæˆ:

```markdown
# Build Instructions

## Prerequisites
- **Build Tool**: [Tool name and version]
- **Dependencies**: [List all required dependencies]
- **Environment Variables**: [List required env vars]
- **System Requirements**: [OS, memory, disk space]

## Build Steps

### 1. Install Dependencies
\`\`\`bash
[Command to install dependencies]
# Example: npm install, mvn dependency:resolve, pip install -r requirements.txt
\`\`\`

### 2. Configure Environment
\`\`\`bash
[Commands to set up environment]
# Example: export variables, configure credentials
\`\`\`

### 3. Build All Units
\`\`\`bash
[Command to build all units]
# Example: mvn clean install, npm run build, brazil-build
\`\`\`

### 4. Verify Build Success
- **Expected Output**: [Describe successful build output]
- **Build Artifacts**: [List generated artifacts and locations]
- **Common Warnings**: [Note any acceptable warnings]

## Troubleshooting

### Build Fails with Dependency Errors
- **Cause**: [Common causes]
- **Solution**: [Step-by-step fix]

### Build Fails with Compilation Errors
- **Cause**: [Common causes]
- **Solution**: [Step-by-step fix]
```
```markdown
# Build Instructions

## Prerequisites
- **Build Tool**: [Tool name and version]
- **Dependencies**: [List all required dependencies]
- **Environment Variables**: [List required env vars]
- **System Requirements**: [OS, memory, disk space]

## Build Steps

### 1. Install Dependencies
```bash
[Command to install dependencies]
# Example: npm install, mvn dependency:resolve, pip install -r requirements.txt
```

### 2. Configure Environment
```bash
[Commands to set up environment]
# Example: export variables, configure credentials
```

### 3. Build All Units
```bash
[Command to build all units]
# Example: mvn clean install, npm run build, brazil-build
```

### 4. Verify Build Success
- **Expected Output**: [Describe successful build output]
- **Build Artifacts**: [List generated artifacts and locations]
- **Common Warnings**: [Note any acceptable warnings]

## Troubleshooting

### Build Fails with Dependency Errors
- **Cause**: [Common causes]
- **Solution**: [Step-by-step fix]

### Build Fails with Compilation Errors
- **Cause**: [Common causes]
- **Solution**: [Step-by-step fix]
```

```markdown
# Build Instructions

## Prerequisites
- **Build Tool**: [Tool name and version]
- **Dependencies**: [List all required dependencies]
- **Environment Variables**: [List required env vars]
- **System Requirements**: [OS, memory, disk space]

## Build Steps

### 1. Install Dependencies
```bash
[Command to install dependencies]
# Example: npm install, mvn dependency:resolve, pip install -r requirements.txt
```

### 2. Configure Environment
```bash
[Commands to set up environment]
# Example: export variables, configure credentials
```

### 3. Build All Units
```bash
[Command to build all units]
# Example: mvn clean install, npm run build, brazil-build
```

### 4. Verify Build Success
- **Expected Output**: [Describe successful build output]
- **Build Artifacts**: [List generated artifacts and locations]
- **Common Warnings**: [Note any acceptable warnings]

## Troubleshooting

### Build Fails with Dependency Errors
- **Cause**: [Common causes]
- **Solution**: [Step-by-step fix]

### Build Fails with Compilation Errors
- **Cause**: [Common causes]
- **Solution**: [Step-by-step fix]
```

---
---

---

## Step 3: Generate Unit Test Execution Instructions
## ã‚¹ãƒ†ãƒƒãƒ— 3: ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œæ‰‹é †ã®ç”Ÿæˆ

## ã‚¹ãƒ†ãƒƒãƒ— 3: ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œæ‰‹é †ã®ç”Ÿæˆ

Create `aidlc-docs/construction/build-and-test/unit-test-instructions.md`:
`aidlc-docs/construction/build-and-test/unit-test-instructions.md` ã‚’ä½œæˆ:

`aidlc-docs/construction/build-and-test/unit-test-instructions.md` ã‚’ä½œæˆ:

```markdown
# Unit Test Execution

## Run Unit Tests

### 1. Execute All Unit Tests
\`\`\`bash
[Command to run all unit tests]
# Example: mvn test, npm test, pytest tests/unit
\`\`\`

### 2. Review Test Results
- **Expected**: [X] tests pass, 0 failures
- **Test Coverage**: [Expected coverage percentage]
- **Test Report Location**: [Path to test reports]

### 3. Fix Failing Tests
If tests fail:
1. Review test output in [location]
2. Identify failing test cases
3. Fix code issues
4. Rerun tests until all pass
```
```markdown
# Unit Test Execution

## Run Unit Tests

### 1. Execute All Unit Tests
```bash
[Command to run all unit tests]
# Example: mvn test, npm test, pytest tests/unit
```

### 2. Review Test Results
- **Expected**: [X] tests pass, 0 failures
- **Test Coverage**: [Expected coverage percentage]
- **Test Report Location**: [Path to test reports]

### 3. Fix Failing Tests
If tests fail:
1. Review test output in [location]
2. Identify failing test cases
3. Fix code issues
4. Rerun tests until all pass
```

```markdown
# Unit Test Execution

## Run Unit Tests

### 1. Execute All Unit Tests
```bash
[Command to run all unit tests]
# Example: mvn test, npm test, pytest tests/unit
```

### 2. Review Test Results
- **Expected**: [X] tests pass, 0 failures
- **Test Coverage**: [Expected coverage percentage]
- **Test Report Location**: [Path to test reports]

### 3. Fix Failing Tests
If tests fail:
1. Review test output in [location]
2. Identify failing test cases
3. Fix code issues
4. Rerun tests until all pass
```

---
---

---

## Step 4: Generate Integration Test Instructions
## ã‚¹ãƒ†ãƒƒãƒ— 4: çµ±åˆãƒ†ã‚¹ãƒˆæ‰‹é †ã®ç”Ÿæˆ

## ã‚¹ãƒ†ãƒƒãƒ— 4: çµ±åˆãƒ†ã‚¹ãƒˆæ‰‹é †ã®ç”Ÿæˆ

Create `aidlc-docs/construction/build-and-test/integration-test-instructions.md`:
`aidlc-docs/construction/build-and-test/integration-test-instructions.md` ã‚’ä½œæˆ:

`aidlc-docs/construction/build-and-test/integration-test-instructions.md` ã‚’ä½œæˆ:

```markdown
# Integration Test Instructions

## Purpose
Test interactions between units/services to ensure they work together correctly.

## Test Scenarios

### Scenario 1: [Unit A] â†’ [Unit B] Integration
- **Description**: [What is being tested]
- **Setup**: [Required test environment setup]
- **Test Steps**: [Step-by-step test execution]
- **Expected Results**: [What should happen]
- **Cleanup**: [How to clean up after test]

### Scenario 2: [Unit B] â†’ [Unit C] Integration
[Similar structure]

## Setup Integration Test Environment

### 1. Start Required Services
\`\`\`bash
[Commands to start services]
# Example: docker-compose up, start test database
\`\`\`

### 2. Configure Service Endpoints
\`\`\`bash
[Commands to configure endpoints]
# Example: export API_URL=http://localhost:8080
\`\`\`

## Run Integration Tests

### 1. Execute Integration Test Suite
\`\`\`bash
[Command to run integration tests]
# Example: mvn integration-test, npm run test:integration
\`\`\`

### 2. Verify Service Interactions
- **Test Scenarios**: [List key integration test scenarios]
- **Expected Results**: [Describe expected outcomes]
- **Logs Location**: [Where to check logs]

### 3. Cleanup
\`\`\`bash
[Commands to clean up test environment]
# Example: docker-compose down, stop test services
\`\`\`
```
```markdown
# Integration Test Instructions

## Purpose
Test interactions between units/services to ensure they work together correctly.

## Test Scenarios

### Scenario 1: [Unit A] â†’ [Unit B] Integration
- **Description**: [What is being tested]
- **Setup**: [Required test environment setup]
- **Test Steps**: [Step-by-step test execution]
- **Expected Results**: [What should happen]
- **Cleanup**: [How to clean up after test]

### Scenario 2: [Unit B] â†’ [Unit C] Integration
[Similar structure]

## Setup Integration Test Environment

### 1. Start Required Services
```bash
[Commands to start services]
# Example: docker-compose up, start test database
```

### 2. Configure Service Endpoints
```bash
[Commands to configure endpoints]
# Example: export API_URL=http://localhost:8080
```

## Run Integration Tests

### 1. Execute Integration Test Suite
```bash
[Command to run integration tests]
# Example: mvn integration-test, npm run test:integration
```

### 2. Verify Service Interactions
- **Test Scenarios**: [List key integration test scenarios]
- **Expected Results**: [Describe expected outcomes]
- **Logs Location**: [Where to check logs]

### 3. Cleanup
```bash
[Commands to clean up test environment]
# Example: docker-compose down, stop test services
```
```

```markdown
# Integration Test Instructions

## Purpose
Test interactions between units/services to ensure they work together correctly.

## Test Scenarios

### Scenario 1: [Unit A] â†’ [Unit B] Integration
- **Description**: [What is being tested]
- **Setup**: [Required test environment setup]
- **Test Steps**: [Step-by-step test execution]
- **Expected Results**: [What should happen]
- **Cleanup**: [How to clean up after test]

### Scenario 2: [Unit B] â†’ [Unit C] Integration
[Similar structure]

## Setup Integration Test Environment

### 1. Start Required Services
```bash
[Commands to start services]
# Example: docker-compose up, start test database
```

### 2. Configure Service Endpoints
```bash
[Commands to configure endpoints]
# Example: export API_URL=http://localhost:8080
```

## Run Integration Tests

### 1. Execute Integration Test Suite
```bash
[Command to run integration tests]
# Example: mvn integration-test, npm run test:integration
```

### 2. Verify Service Interactions
- **Test Scenarios**: [List key integration test scenarios]
- **Expected Results**: [Describe expected outcomes]
- **Logs Location**: [Where to check logs]

### 3. Cleanup
```bash
[Commands to clean up test environment]
# Example: docker-compose down, stop test services
```
```

---
---

---

## Step 5: Generate Performance Test Instructions (If Applicable)
## ã‚¹ãƒ†ãƒƒãƒ— 5: æ€§èƒ½ãƒ†ã‚¹ãƒˆæ‰‹é †ã®ç”Ÿæˆï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰

## ã‚¹ãƒ†ãƒƒãƒ— 5: æ€§èƒ½ãƒ†ã‚¹ãƒˆæ‰‹é †ã®ç”Ÿæˆï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰

Create `aidlc-docs/construction/build-and-test/performance-test-instructions.md`:
`aidlc-docs/construction/build-and-test/performance-test-instructions.md` ã‚’ä½œæˆ:

`aidlc-docs/construction/build-and-test/performance-test-instructions.md` ã‚’ä½œæˆ:

```markdown
# Performance Test Instructions

## Purpose
Validate system performance under load to ensure it meets requirements.

## Performance Requirements
- **Response Time**: < [X]ms for [Y]% of requests
- **Throughput**: [X] requests/second
- **Concurrent Users**: Support [X] concurrent users
- **Error Rate**: < [X]%

## Setup Performance Test Environment

### 1. Prepare Test Environment
\`\`\`bash
[Commands to set up performance testing]
# Example: scale services, configure load balancers
\`\`\`

### 2. Configure Test Parameters
- **Test Duration**: [X] minutes
- **Ramp-up Time**: [X] seconds
- **Virtual Users**: [X] users

## Run Performance Tests

### 1. Execute Load Tests
\`\`\`bash
[Command to run load tests]
# Example: jmeter -n -t test.jmx, k6 run script.js
\`\`\`

### 2. Execute Stress Tests
\`\`\`bash
[Command to run stress tests]
# Example: gradually increase load until failure
\`\`\`

### 3. Analyze Performance Results
- **Response Time**: [Actual vs Expected]
- **Throughput**: [Actual vs Expected]
- **Error Rate**: [Actual vs Expected]
- **Bottlenecks**: [Identified bottlenecks]
- **Results Location**: [Path to performance reports]

## Performance Optimization

If performance doesn't meet requirements:
1. Identify bottlenecks from test results
2. Optimize code/queries/configurations
3. Rerun tests to validate improvements
```
```markdown
# Performance Test Instructions

## Purpose
Validate system performance under load to ensure it meets requirements.

## Performance Requirements
- **Response Time**: < [X]ms for [Y]% of requests
- **Throughput**: [X] requests/second
- **Concurrent Users**: Support [X] concurrent users
- **Error Rate**: < [X]%

## Setup Performance Test Environment

### 1. Prepare Test Environment
```bash
[Commands to set up performance testing]
# Example: scale services, configure load balancers
```

### 2. Configure Test Parameters
- **Test Duration**: [X] minutes
- **Ramp-up Time**: [X] seconds
- **Virtual Users**: [X] users

## Run Performance Tests

### 1. Execute Load Tests
```bash
[Command to run load tests]
# Example: jmeter -n -t test.jmx, k6 run script.js
```

### 2. Execute Stress Tests
```bash
[Command to run stress tests]
# Example: gradually increase load until failure
```

### 3. Analyze Performance Results
- **Response Time**: [Actual vs Expected]
- **Throughput**: [Actual vs Expected]
- **Error Rate**: [Actual vs Expected]
- **Bottlenecks**: [Identified bottlenecks]
- **Results Location**: [Path to performance reports]

## Performance Optimization

If performance doesn't meet requirements:
1. Identify bottlenecks from test results
2. Optimize code/queries/configurations
3. Rerun tests to validate improvements
```

```markdown
# Performance Test Instructions

## Purpose
Validate system performance under load to ensure it meets requirements.

## Performance Requirements
- **Response Time**: < [X]ms for [Y]% of requests
- **Throughput**: [X] requests/second
- **Concurrent Users**: Support [X] concurrent users
- **Error Rate**: < [X]%

## Setup Performance Test Environment

### 1. Prepare Test Environment
```bash
[Commands to set up performance testing]
# Example: scale services, configure load balancers
```

### 2. Configure Test Parameters
- **Test Duration**: [X] minutes
- **Ramp-up Time**: [X] seconds
- **Virtual Users**: [X] users

## Run Performance Tests

### 1. Execute Load Tests
```bash
[Command to run load tests]
# Example: jmeter -n -t test.jmx, k6 run script.js
```

### 2. Execute Stress Tests
```bash
[Command to run stress tests]
# Example: gradually increase load until failure
```

### 3. Analyze Performance Results
- **Response Time**: [Actual vs Expected]
- **Throughput**: [Actual vs Expected]
- **Error Rate**: [Actual vs Expected]
- **Bottlenecks**: [Identified bottlenecks]
- **Results Location**: [Path to performance reports]

## Performance Optimization

If performance doesn't meet requirements:
1. Identify bottlenecks from test results
2. Optimize code/queries/configurations
3. Rerun tests to validate improvements
```

---
---

---

## Step 6: Generate Additional Test Instructions (As Needed)
## ã‚¹ãƒ†ãƒƒãƒ— 6: è¿½åŠ ãƒ†ã‚¹ãƒˆæ‰‹é †ã®ç”Ÿæˆï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰

## ã‚¹ãƒ†ãƒƒãƒ— 6: è¿½åŠ ãƒ†ã‚¹ãƒˆæ‰‹é †ã®ç”Ÿæˆï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰

Based on project requirements, generate additional test instruction files:
ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¦ä»¶ã«åŸºã¥ã„ã¦è¿½åŠ ã®æ‰‹é †ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ:

ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¦ä»¶ã«åŸºã¥ã„ã¦è¿½åŠ ã®æ‰‹é †ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ:

### Contract Tests (For Microservices)
Create `aidlc-docs/construction/build-and-test/contract-test-instructions.md`:
- API contract validation between services
- Consumer-driven contract testing
- Schema validation
### å¥‘ç´„ãƒ†ã‚¹ãƒˆï¼ˆãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹å‘ã‘ï¼‰
`aidlc-docs/construction/build-and-test/contract-test-instructions.md` ã‚’ä½œæˆ:
- ã‚µãƒ¼ãƒ“ã‚¹é–“ã® API å¥‘ç´„æ¤œè¨¼
- ã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒé§†å‹•å¥‘ç´„ãƒ†ã‚¹ãƒˆ
- ã‚¹ã‚­ãƒ¼ãƒæ¤œè¨¼

### å¥‘ç´„ãƒ†ã‚¹ãƒˆï¼ˆãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹å‘ã‘ï¼‰
`aidlc-docs/construction/build-and-test/contract-test-instructions.md` ã‚’ä½œæˆ:
- ã‚µãƒ¼ãƒ“ã‚¹é–“ã® API å¥‘ç´„æ¤œè¨¼
- ã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒé§†å‹•å¥‘ç´„ãƒ†ã‚¹ãƒˆ
- ã‚¹ã‚­ãƒ¼ãƒæ¤œè¨¼

### Security Tests
Create `aidlc-docs/construction/build-and-test/security-test-instructions.md`:
- Vulnerability scanning
- Dependency security checks
- Authentication/authorization testing
- Input validation testing
### ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ†ã‚¹ãƒˆ
`aidlc-docs/construction/build-and-test/security-test-instructions.md` ã‚’ä½œæˆ:
- è„†å¼±æ€§ã‚¹ã‚­ãƒ£ãƒ³
- ä¾å­˜é–¢ä¿‚ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯
- èªè¨¼/èªå¯ãƒ†ã‚¹ãƒˆ
- å…¥åŠ›æ¤œè¨¼ãƒ†ã‚¹ãƒˆ

### ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ†ã‚¹ãƒˆ
`aidlc-docs/construction/build-and-test/security-test-instructions.md` ã‚’ä½œæˆ:
- è„†å¼±æ€§ã‚¹ã‚­ãƒ£ãƒ³
- ä¾å­˜é–¢ä¿‚ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯
- èªè¨¼/èªå¯ãƒ†ã‚¹ãƒˆ
- å…¥åŠ›æ¤œè¨¼ãƒ†ã‚¹ãƒˆ

### End-to-End Tests
Create `aidlc-docs/construction/build-and-test/e2e-test-instructions.md`:
- Complete user workflow testing
- Cross-service scenarios
- UI testing (if applicable)
### E2E ãƒ†ã‚¹ãƒˆ
`aidlc-docs/construction/build-and-test/e2e-test-instructions.md` ã‚’ä½œæˆ:
- å®Œå…¨ãªãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆ
- ã‚¯ãƒ­ã‚¹ã‚µãƒ¼ãƒ“ã‚¹ã‚·ãƒŠãƒªã‚ª
- UI ãƒ†ã‚¹ãƒˆï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰

### E2E ãƒ†ã‚¹ãƒˆ
`aidlc-docs/construction/build-and-test/e2e-test-instructions.md` ã‚’ä½œæˆ:
- å®Œå…¨ãªãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆ
- ã‚¯ãƒ­ã‚¹ã‚µãƒ¼ãƒ“ã‚¹ã‚·ãƒŠãƒªã‚ª
- UI ãƒ†ã‚¹ãƒˆï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰

---
---

---

## Step 7: Generate Test Summary
## ã‚¹ãƒ†ãƒƒãƒ— 7: ãƒ†ã‚¹ãƒˆã‚µãƒãƒªãƒ¼ã®ç”Ÿæˆ

## ã‚¹ãƒ†ãƒƒãƒ— 7: ãƒ†ã‚¹ãƒˆã‚µãƒãƒªãƒ¼ã®ç”Ÿæˆ

Create `aidlc-docs/construction/build-and-test/build-and-test-summary.md`:
`aidlc-docs/construction/build-and-test/build-and-test-summary.md` ã‚’ä½œæˆ:

`aidlc-docs/construction/build-and-test/build-and-test-summary.md` ã‚’ä½œæˆ:

```markdown
# Build and Test Summary

## Build Status
- **Build Tool**: [Tool name]
- **Build Status**: [Success/Failed]
- **Build Artifacts**: [List artifacts]
- **Build Time**: [Duration]

## Test Execution Summary

### Unit Tests
- **Total Tests**: [X]
- **Passed**: [X]
- **Failed**: [X]
- **Coverage**: [X]%
- **Status**: [Pass/Fail]

### Integration Tests
- **Test Scenarios**: [X]
- **Passed**: [X]
- **Failed**: [X]
- **Status**: [Pass/Fail]

### Performance Tests
- **Response Time**: [Actual] (Target: [Expected])
- **Throughput**: [Actual] (Target: [Expected])
- **Error Rate**: [Actual] (Target: [Expected])
- **Status**: [Pass/Fail]

### Additional Tests
- **Contract Tests**: [Pass/Fail/N/A]
- **Security Tests**: [Pass/Fail/N/A]
- **E2E Tests**: [Pass/Fail/N/A]

## Overall Status
- **Build**: [Success/Failed]
- **All Tests**: [Pass/Fail]
- **Ready for Operations**: [Yes/No]

## Next Steps
[If all pass]: Ready to proceed to Operations phase for deployment planning
[If failures]: Address failing tests and rebuild
```
```markdown
# Build and Test Summary

## Build Status
- **Build Tool**: [Tool name]
- **Build Status**: [Success/Failed]
- **Build Artifacts**: [List artifacts]
- **Build Time**: [Duration]

## Test Execution Summary

### Unit Tests
- **Total Tests**: [X]
- **Passed**: [X]
- **Failed**: [X]
- **Coverage**: [X]%
- **Status**: [Pass/Fail]

### Integration Tests
- **Test Scenarios**: [X]
- **Passed**: [X]
- **Failed**: [X]
- **Status**: [Pass/Fail]

### Performance Tests
- **Response Time**: [Actual] (Target: [Expected])
- **Throughput**: [Actual] (Target: [Expected])
- **Error Rate**: [Actual] (Target: [Expected])
- **Status**: [Pass/Fail]

### Additional Tests
- **Contract Tests**: [Pass/Fail/N/A]
- **Security Tests**: [Pass/Fail/N/A]
- **E2E Tests**: [Pass/Fail/N/A]

## Overall Status
- **Build**: [Success/Failed]
- **All Tests**: [Pass/Fail]
- **Ready for Operations**: [Yes/No]

## Next Steps
[If all pass]: Ready to proceed to Operations phase for deployment planning
[If failures]: Address failing tests and rebuild
```

```markdown
# Build and Test Summary

## Build Status
- **Build Tool**: [Tool name]
- **Build Status**: [Success/Failed]
- **Build Artifacts**: [List artifacts]
- **Build Time**: [Duration]

## Test Execution Summary

### Unit Tests
- **Total Tests**: [X]
- **Passed**: [X]
- **Failed**: [X]
- **Coverage**: [X]%
- **Status**: [Pass/Fail]

### Integration Tests
- **Test Scenarios**: [X]
- **Passed**: [X]
- **Failed**: [X]
- **Status**: [Pass/Fail]

### Performance Tests
- **Response Time**: [Actual] (Target: [Expected])
- **Throughput**: [Actual] (Target: [Expected])
- **Error Rate**: [Actual] (Target: [Expected])
- **Status**: [Pass/Fail]

### Additional Tests
- **Contract Tests**: [Pass/Fail/N/A]
- **Security Tests**: [Pass/Fail/N/A]
- **E2E Tests**: [Pass/Fail/N/A]

## Overall Status
- **Build**: [Success/Failed]
- **All Tests**: [Pass/Fail]
- **Ready for Operations**: [Yes/No]

## Next Steps
[If all pass]: Ready to proceed to Operations phase for deployment planning
[If failures]: Address failing tests and rebuild
```

---
---

---

## Step 8: Update State Tracking
## ã‚¹ãƒ†ãƒƒãƒ— 8: çŠ¶æ…‹è¿½è·¡ã®æ›´æ–°

## ã‚¹ãƒ†ãƒƒãƒ— 8: çŠ¶æ…‹è¿½è·¡ã®æ›´æ–°

Update `aidlc-docs/aidlc-state.md`:
- Mark Build and Test stage as complete
- Update current status
`aidlc-docs/aidlc-state.md` ã‚’æ›´æ–°:
- Build and Test ã‚¹ãƒ†ãƒ¼ã‚¸ã‚’å®Œäº†ã«ã™ã‚‹
- ç¾åœ¨çŠ¶æ³ã‚’æ›´æ–°

`aidlc-docs/aidlc-state.md` ã‚’æ›´æ–°:
- Build and Test ã‚¹ãƒ†ãƒ¼ã‚¸ã‚’å®Œäº†ã«ã™ã‚‹
- ç¾åœ¨çŠ¶æ³ã‚’æ›´æ–°

---
---

---

## Step 9: Present Results to User
## ã‚¹ãƒ†ãƒƒãƒ— 9: çµæœã®æç¤º

## ã‚¹ãƒ†ãƒƒãƒ— 9: çµæœã®æç¤º

Present comprehensive message:
åŒ…æ‹¬çš„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æç¤º:

åŒ…æ‹¬çš„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æç¤º:

```
"ğŸ”¨ Build and Test Complete!

**Build Status**: [Success/Failed]

**Test Results**:
âœ… Unit Tests: [X] passed
âœ… Integration Tests: [X] scenarios passed
âœ… Performance Tests: [Status]
âœ… Additional Tests: [Status]

**Generated Files**:
1. âœ… build-instructions.md
2. âœ… unit-test-instructions.md
3. âœ… integration-test-instructions.md
4. âœ… performance-test-instructions.md (if applicable)
5. âœ… [additional test files as needed]
6. âœ… build-and-test-summary.md

Review the summary in aidlc-docs/construction/build-and-test/build-and-test-summary.md

**Ready to proceed to Operations stage for deployment planning?""
```
```
"ğŸ”¨ Build and Test Complete!

**Build Status**: [Success/Failed]

**Test Results**:
âœ… Unit Tests: [X] passed
âœ… Integration Tests: [X] scenarios passed
âœ… Performance Tests: [Status]
âœ… Additional Tests: [Status]

**Generated Files**:
1. âœ… build-instructions.md
2. âœ… unit-test-instructions.md
3. âœ… integration-test-instructions.md
4. âœ… performance-test-instructions.md (if applicable)
5. âœ… [additional test files as needed]
6. âœ… build-and-test-summary.md

Review the summary in aidlc-docs/construction/build-and-test/build-and-test-summary.md

**Ready to proceed to Operations stage for deployment planning?""
```

```
"ğŸ”¨ Build and Test Complete!

**Build Status**: [Success/Failed]

**Test Results**:
âœ… Unit Tests: [X] passed
âœ… Integration Tests: [X] scenarios passed
âœ… Performance Tests: [Status]
âœ… Additional Tests: [Status]

**Generated Files**:
1. âœ… build-instructions.md
2. âœ… unit-test-instructions.md
3. âœ… integration-test-instructions.md
4. âœ… performance-test-instructions.md (if applicable)
5. âœ… [additional test files as needed]
6. âœ… build-and-test-summary.md

Review the summary in aidlc-docs/construction/build-and-test/build-and-test-summary.md

**Ready to proceed to Operations stage for deployment planning?""
```

---
---

---

## Step 10: Log Interaction
## ã‚¹ãƒ†ãƒƒãƒ— 10: å–ã‚Šæ‰±ã„ã®è¨˜éŒ²

## ã‚¹ãƒ†ãƒƒãƒ— 10: å–ã‚Šæ‰±ã„ã®è¨˜éŒ²

**MANDATORY**: Log the phase completion in `aidlc-docs/audit.md`:
**å¿…é ˆ**: `aidlc-docs/audit.md` ã«ãƒ•ã‚§ãƒ¼ã‚ºå®Œäº†ã‚’è¨˜éŒ²:

**å¿…é ˆ**: `aidlc-docs/audit.md` ã«ãƒ•ã‚§ãƒ¼ã‚ºå®Œäº†ã‚’è¨˜éŒ²:

```markdown
## Build and Test Stage
**Timestamp**: [ISO timestamp]
**Build Status**: [Success/Failed]
**Test Status**: [Pass/Fail]
**Files Generated**:
- build-instructions.md
- unit-test-instructions.md
- integration-test-instructions.md
- performance-test-instructions.md
- build-and-test-summary.md

---
```
```markdown
## Build and Test Stage
**Timestamp**: [ISO timestamp]
**Build Status**: [Success/Failed]
**Test Status**: [Pass/Fail]
**Files Generated**:
- build-instructions.md
- unit-test-instructions.md
- integration-test-instructions.md
- performance-test-instructions.md
- build-and-test-summary.md

---
```

```markdown
## Build and Test Stage
**Timestamp**: [ISO timestamp]
**Build Status**: [Success/Failed]
**Test Status**: [Pass/Fail]
**Files Generated**:
- build-instructions.md
- unit-test-instructions.md
- integration-test-instructions.md
- performance-test-instructions.md
- build-and-test-summary.md

---
```
